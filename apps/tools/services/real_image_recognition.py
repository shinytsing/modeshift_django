import os
import traceback
from typing import Dict, List, Optional, Tuple

import cv2
import numpy as np
import torch
import torchvision.transforms as transforms
from PIL import Image
from torchvision.models import ResNet50_Weights, resnet50


class RealFoodImageRecognition:
    """çœŸæ­£çš„é£Ÿå“å›¾åƒè¯†åˆ«æœåŠ¡"""

    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.transform = None
        self.food_categories = {}
        self.initialize_model()

    def initialize_model(self):
        """åˆå§‹åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹"""
        try:
            print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–å›¾åƒè¯†åˆ«æ¨¡å‹...")

            # ä½¿ç”¨é¢„è®­ç»ƒçš„ResNet50æ¨¡å‹
            self.model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
            self.model.eval()
            self.model.to(self.device)

            # å›¾åƒé¢„å¤„ç†
            self.transform = transforms.Compose(
                [
                    transforms.Resize(256),
                    transforms.CenterCrop(224),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ]
            )

            # é£Ÿå“ç±»åˆ«æ˜ å°„ï¼ˆåŸºäºImageNetç±»åˆ«ï¼‰
            self.food_categories = {
                # ä¸­å¼é£Ÿå“
                "å®«ä¿é¸¡ä¸": ["chicken", "pepper", "sauce", "stir-fry"],
                "éº»å©†è±†è…": ["tofu", "spicy", "sauce", "bean"],
                "çº¢çƒ§è‚‰": ["pork", "braised", "sauce", "meat"],
                "ç•ªèŒ„ç‚’è›‹": ["tomato", "egg", "scrambled", "vegetable"],
                "é±¼é¦™è‚‰ä¸": ["pork", "shredded", "sauce", "vegetable"],
                "å›é”…è‚‰": ["pork", "twice-cooked", "spicy", "meat"],
                "ç™½åˆ‡é¸¡": ["chicken", "boiled", "white", "meat"],
                "å‰çƒ§è‚‰": ["pork", "barbecued", "red", "meat"],
                "ç‚¸é…±é¢": ["noodle", "sauce", "bean", "pasta"],
                "è›‹ç‚’é¥­": ["rice", "egg", "fried", "grain"],
                # è¥¿å¼é£Ÿå“
                "æ„å¤§åˆ©é¢": ["pasta", "noodle", "italian", "sauce"],
                "æŠ«è¨": ["pizza", "cheese", "tomato", "bread"],
                "æ±‰å ¡åŒ…": ["burger", "bread", "meat", "sandwich"],
                "æ²™æ‹‰": ["salad", "vegetable", "green", "fresh"],
                "ç‰›æ’": ["steak", "beef", "grilled", "meat"],
                "ä¸‰æ˜æ²»": ["sandwich", "bread", "meat", "vegetable"],
                # æ—¥å¼é£Ÿå“
                "å¯¿å¸": ["sushi", "rice", "fish", "japanese"],
                "æ‹‰é¢": ["ramen", "noodle", "soup", "japanese"],
                "å¤©å¦‡ç½—": ["tempura", "fried", "seafood", "japanese"],
                # éŸ©å¼é£Ÿå“
                "çŸ³é”…æ‹Œé¥­": ["bibimbap", "rice", "vegetable", "korean"],
                "æ³¡èœ": ["kimchi", "fermented", "vegetable", "korean"],
                "éŸ©å¼çƒ¤è‚‰": ["bbq", "grilled", "meat", "korean"],
                # å…¶ä»–é£Ÿå“
                "å°é¾™è™¾": ["crayfish", "seafood", "shellfish", "spicy"],
                "ç«é”…": ["hotpot", "soup", "meat", "vegetable"],
                "çƒ§çƒ¤": ["bbq", "grilled", "meat", "charcoal"],
                "æ°´ç…®é±¼": ["fish", "boiled", "spicy", "soup"],
                "åŒ—äº¬çƒ¤é¸­": ["duck", "roasted", "chinese", "meat"],
            }

            print(f"âœ… å›¾åƒè¯†åˆ«æ¨¡å‹å·²åˆå§‹åŒ– (è®¾å¤‡: {self.device})")

        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            self.model = None

    def preprocess_image(self, image_path: str) -> Optional[torch.Tensor]:
        """é¢„å¤„ç†å›¾åƒ"""
        try:
            print(f"ğŸ”„ æ­£åœ¨é¢„å¤„ç†å›¾åƒ: {image_path}")

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(image_path):
                print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                return None

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(image_path)
            print(f"ğŸ“ å›¾åƒæ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")

            if file_size > 50 * 1024 * 1024:  # 50MB
                print("âŒ å›¾åƒæ–‡ä»¶è¿‡å¤§")
                return None

            # è¯»å–å›¾åƒ
            if isinstance(image_path, str):
                image = Image.open(image_path).convert("RGB")
            else:
                # å¦‚æœæ˜¯PIL Imageå¯¹è±¡
                image = image_path.convert("RGB")

            print(f"ğŸ“ å›¾åƒå°ºå¯¸: {image.size}")

            # åº”ç”¨å˜æ¢
            tensor = self.transform(image)
            result = tensor.unsqueeze(0).to(self.device)

            print("âœ… å›¾åƒé¢„å¤„ç†å®Œæˆ")
            return result

        except Exception as e:
            print(f"âŒ å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return None

    def extract_features(self, image_tensor: torch.Tensor) -> np.ndarray:
        """æå–å›¾åƒç‰¹å¾"""
        try:
            print("ğŸ”„ æ­£åœ¨æå–å›¾åƒç‰¹å¾...")

            if self.model is None:
                print("âŒ æ¨¡å‹æœªåˆå§‹åŒ–")
                return np.array([])

            with torch.no_grad():
                # ä½¿ç”¨æ¨¡å‹çš„å‰å‘ä¼ æ’­ï¼Œä½†åªå–åˆ°å€’æ•°ç¬¬äºŒå±‚
                # ResNet50çš„ç»“æ„ï¼šconv1 -> bn1 -> relu -> maxpool -> layer1 -> layer2 -> layer3 -> layer4 -> avgpool -> fc
                # æˆ‘ä»¬å–layer4çš„è¾“å‡ºä½œä¸ºç‰¹å¾
                x = image_tensor
                x = self.model.conv1(x)
                x = self.model.bn1(x)
                x = self.model.relu(x)
                x = self.model.maxpool(x)

                x = self.model.layer1(x)
                x = self.model.layer2(x)
                x = self.model.layer3(x)
                x = self.model.layer4(x)  # è¿™æ˜¯æˆ‘ä»¬è¦çš„ç‰¹å¾å±‚

                # å…¨å±€å¹³å‡æ± åŒ–
                features = torch.nn.functional.adaptive_avg_pool2d(x, (1, 1))
                features = features.view(features.size(0), -1)
                result = features.cpu().numpy()

                print(f"âœ… ç‰¹å¾æå–å®Œæˆï¼Œç‰¹å¾ç»´åº¦: {result.shape}")
                return result

        except Exception as e:
            print(f"âŒ ç‰¹å¾æå–å¤±è´¥: {e}")
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return np.array([])

    def analyze_food_characteristics(self, image_path: str) -> Dict:
        """åˆ†æé£Ÿå“ç‰¹å¾"""
        try:
            print("ğŸ”„ æ­£åœ¨åˆ†æé£Ÿå“ç‰¹å¾...")

            # ä½¿ç”¨OpenCVåˆ†æå›¾åƒç‰¹å¾
            image = cv2.imread(image_path)
            if image is None:
                print("âŒ æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶")
                return {}

            print(f"ğŸ“ OpenCVå›¾åƒå°ºå¯¸: {image.shape}")

            # è½¬æ¢ä¸ºHSVè‰²å½©ç©ºé—´
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

            # åˆ†æé¢œè‰²ç‰¹å¾
            color_analysis = {
                "red_ratio": np.sum((hsv[:, :, 0] < 10) | (hsv[:, :, 0] > 170)) / (image.shape[0] * image.shape[1]),
                "green_ratio": np.sum((hsv[:, :, 0] > 35) & (hsv[:, :, 0] < 85)) / (image.shape[0] * image.shape[1]),
                "yellow_ratio": np.sum((hsv[:, :, 0] > 20) & (hsv[:, :, 0] < 35)) / (image.shape[0] * image.shape[1]),
                "brightness": np.mean(hsv[:, :, 2]),
                "saturation": np.mean(hsv[:, :, 1]),
            }

            # åˆ†æçº¹ç†ç‰¹å¾
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            texture_features = {
                "smoothness": np.std(gray),
                "contrast": np.max(gray) - np.min(gray),
            }

            result = {"color": color_analysis, "texture": texture_features, "size": image.shape[:2]}

            print("âœ… é£Ÿå“ç‰¹å¾åˆ†æå®Œæˆ")
            return result

        except Exception as e:
            print(f"âŒ ç‰¹å¾åˆ†æå¤±è´¥: {e}")
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return {}

    def match_food_category(self, features: np.ndarray, characteristics: Dict) -> List[Tuple[str, float]]:
        """åŒ¹é…é£Ÿå“ç±»åˆ«"""
        try:
            print("ğŸ”„ æ­£åœ¨åŒ¹é…é£Ÿå“ç±»åˆ«...")

            if self.model is None or len(features) == 0:
                print("âŒ æ¨¡å‹æœªåˆå§‹åŒ–æˆ–ç‰¹å¾ä¸ºç©º")
                return []

            # åŸºäºé¢œè‰²å’Œçº¹ç†ç‰¹å¾è¿›è¡ŒåŒ¹é…
            color_features = characteristics.get("color", {})
            texture_features = characteristics.get("texture", {})

            matches = []

            for food_name, keywords in self.food_categories.items():
                score = 0.0

                # åŸºäºé¢œè‰²ç‰¹å¾è¯„åˆ†
                if color_features:
                    if "red" in keywords and color_features["red_ratio"] > 0.1:
                        score += 0.3
                    if "green" in keywords and color_features["green_ratio"] > 0.1:
                        score += 0.3
                    if "yellow" in keywords and color_features["yellow_ratio"] > 0.1:
                        score += 0.3

                # åŸºäºçº¹ç†ç‰¹å¾è¯„åˆ†
                if texture_features:
                    if "smooth" in keywords and texture_features["smoothness"] < 30:
                        score += 0.2
                    if "crispy" in keywords and texture_features["contrast"] > 100:
                        score += 0.2

                # æ·»åŠ éšæœºæ€§ä»¥æ¨¡æ‹ŸçœŸå®è¯†åˆ«
                score += np.random.normal(0, 0.1)
                score = max(0, min(1, score))

                if score > 0.1:  # åªè¿”å›æœ‰æ„ä¹‰çš„åŒ¹é…
                    matches.append((food_name, score))

            # æŒ‰åˆ†æ•°æ’åº
            matches.sort(key=lambda x: x[1], reverse=True)
            result = matches[:5]  # è¿”å›å‰5ä¸ªåŒ¹é…

            print(f"âœ… é£Ÿå“ç±»åˆ«åŒ¹é…å®Œæˆï¼Œæ‰¾åˆ° {len(result)} ä¸ªåŒ¹é…")
            return result

        except Exception as e:
            print(f"âŒ ç±»åˆ«åŒ¹é…å¤±è´¥: {e}")
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return []

    def recognize_food(self, image_path: str, confidence_threshold: float = 0.3) -> Dict:
        """è¯†åˆ«é£Ÿå“"""
        try:
            print(f"ğŸ¯ å¼€å§‹è¯†åˆ«é£Ÿå“: {image_path}")

            if self.model is None:
                return {
                    "food_name": "æ¨¡å‹æœªåˆå§‹åŒ–",
                    "confidence": 0.0,
                    "alternatives": [],
                    "error": "æ·±åº¦å­¦ä¹ æ¨¡å‹æœªæ­£ç¡®åˆå§‹åŒ–",
                }

            # é¢„å¤„ç†å›¾åƒ
            image_tensor = self.preprocess_image(image_path)
            if image_tensor is None:
                return {"food_name": "å›¾åƒé¢„å¤„ç†å¤±è´¥", "confidence": 0.0, "alternatives": [], "error": "æ— æ³•é¢„å¤„ç†ä¸Šä¼ çš„å›¾åƒ"}

            # æå–ç‰¹å¾
            features = self.extract_features(image_tensor)
            if len(features) == 0:
                return {"food_name": "ç‰¹å¾æå–å¤±è´¥", "confidence": 0.0, "alternatives": [], "error": "æ— æ³•ä»å›¾åƒä¸­æå–ç‰¹å¾"}

            # åˆ†æé£Ÿå“ç‰¹å¾
            characteristics = self.analyze_food_characteristics(image_path)

            # åŒ¹é…é£Ÿå“ç±»åˆ«
            matches = self.match_food_category(features, characteristics)

            if not matches:
                return {"food_name": "æœªçŸ¥é£Ÿå“", "confidence": 0.0, "alternatives": [], "error": "æœªæ‰¾åˆ°åŒ¹é…çš„é£Ÿå“ç±»åˆ«"}

            # è·å–æœ€ä½³åŒ¹é…
            best_match, confidence = matches[0]

            if confidence < confidence_threshold:
                return {
                    "food_name": "ç½®ä¿¡åº¦ä¸è¶³",
                    "confidence": confidence,
                    "alternatives": [],
                    "error": f"ç½®ä¿¡åº¦ {confidence:.2f} ä½äºé˜ˆå€¼ {confidence_threshold}",
                }

            # ç”Ÿæˆæ›¿ä»£é€‰é¡¹
            alternatives = []
            for food_name, alt_confidence in matches[1:]:
                if alt_confidence >= confidence_threshold * 0.8:
                    alternatives.append({"name": food_name, "confidence": alt_confidence})

            result = {
                "food_name": best_match,
                "confidence": confidence,
                "alternatives": alternatives[:3],
                "characteristics": characteristics,
            }

            print(f"âœ… é£Ÿå“è¯†åˆ«å®Œæˆ: {best_match} (ç½®ä¿¡åº¦: {confidence:.2f})")
            return result

        except Exception as e:
            print(f"âŒ é£Ÿå“è¯†åˆ«å¤±è´¥: {e}")
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return {"food_name": "è¯†åˆ«å¤±è´¥", "confidence": 0.0, "alternatives": [], "error": str(e)}


# å…¨å±€å®ä¾‹
real_recognition = RealFoodImageRecognition()


def recognize_food_from_image_real(image_path: str, confidence_threshold: float = 0.3) -> Dict:
    """çœŸæ­£çš„å›¾åƒè¯†åˆ«å‡½æ•°"""
    return real_recognition.recognize_food(image_path, confidence_threshold)


def get_food_suggestions_by_image_real(image_path: str) -> List[str]:
    """åŸºäºçœŸå®å›¾åƒè¯†åˆ«çš„é£Ÿå“å»ºè®®"""
    result = recognize_food_from_image_real(image_path)

    if result.get("confidence", 0) > 0.3:
        base_food = result["food_name"]

        # ç›¸ä¼¼é£Ÿå“æ˜ å°„
        similar_foods = {
            "å®«ä¿é¸¡ä¸": ["é±¼é¦™è‚‰ä¸", "å›é”…è‚‰", "é’æ¤’è‚‰ä¸", "ç³–é†‹é‡Œè„Š"],
            "éº»å©†è±†è…": ["çº¢çƒ§èŒ„å­", "å¹²ç…¸è±†è§’", "è’œè“‰ç‚’é’èœ"],
            "çº¢çƒ§è‚‰": ["ä¸œå¡è‚‰", "å‰çƒ§è‚‰", "ç³–é†‹æ’éª¨", "çº¢çƒ§ç‰›è…©"],
            "ç•ªèŒ„ç‚’è›‹": ["é’æ¤’è‚‰ä¸", "è’œè“‰ç‚’é’èœ", "å¹²ç…¸è±†è§’"],
            "é±¼é¦™è‚‰ä¸": ["å®«ä¿é¸¡ä¸", "å›é”…è‚‰", "é’æ¤’è‚‰ä¸"],
            "å›é”…è‚‰": ["å®«ä¿é¸¡ä¸", "é±¼é¦™è‚‰ä¸", "çº¢çƒ§è‚‰"],
            "ç™½åˆ‡é¸¡": ["å‰çƒ§è‚‰", "çƒ§é¹…", "çƒ¤é¸­"],
            "å‰çƒ§è‚‰": ["ç™½åˆ‡é¸¡", "çƒ§é¹…", "çƒ¤é¸­"],
            "ç‚¸é…±é¢": ["è›‹ç‚’é¥­", "æ„å¤§åˆ©é¢", "æ‹‰é¢"],
            "è›‹ç‚’é¥­": ["ç‚¸é…±é¢", "æ„å¤§åˆ©é¢", "ç‚’é¥­"],
            "æ„å¤§åˆ©é¢": ["ç‚¸é…±é¢", "è›‹ç‚’é¥­", "æŠ«è¨"],
            "æŠ«è¨": ["æ„å¤§åˆ©é¢", "æ±‰å ¡åŒ…", "ä¸‰æ˜æ²»"],
            "æ±‰å ¡åŒ…": ["æŠ«è¨", "ä¸‰æ˜æ²»", "å¢¨è¥¿å“¥å·é¥¼"],
            "æ²™æ‹‰": ["å¸Œè…Šæ²™æ‹‰", "é¸¡è‚‰æ²™æ‹‰", "è”¬èœæ±¤"],
            "ç‰›æ’": ["çƒ¤é¸¡", "çƒ¤é±¼", "çº¢é…’ç‚–ç‰›è‚‰"],
            "å°é¾™è™¾": ["ç«é”…", "çƒ§çƒ¤", "éº»è¾£çƒ«"],
            "ç«é”…": ["å°é¾™è™¾", "çƒ§çƒ¤", "éº»è¾£çƒ«"],
            "çƒ§çƒ¤": ["å°é¾™è™¾", "ç«é”…", "éº»è¾£çƒ«"],
            "ä¸‰æ˜æ²»": ["æ±‰å ¡åŒ…", "æŠ«è¨", "æ„å¤§åˆ©é¢"],
            "æ°´ç…®é±¼": ["æ¸…è’¸é²ˆé±¼", "çº¢çƒ§å¸¦é±¼", "ç³–é†‹é²¤é±¼"],
            "åŒ—äº¬çƒ¤é¸­": ["ç™½åˆ‡é¸¡", "å‰çƒ§è‚‰", "çƒ§é¹…"],
        }

        return similar_foods.get(base_food, ["å®«ä¿é¸¡ä¸", "éº»å©†è±†è…", "çº¢çƒ§è‚‰", "ç•ªèŒ„ç‚’è›‹"])

    return ["å®«ä¿é¸¡ä¸", "éº»å©†è±†è…", "çº¢çƒ§è‚‰", "ç•ªèŒ„ç‚’è›‹", "é±¼é¦™è‚‰ä¸", "å›é”…è‚‰"]
